## Задача
Написать web-crawler, который скачивает все страницы с определенного домена (к примеру, habr.com), 
и находит 10 наиболее часто-используемых слов на русском языке, исключая предлоги.
  
## Описание решения
1. Предлоги взяты отсюда: https://bit.ly/2AjvZai  
2. Настройки хранятся в `settings.py`  
     Ограничение по времени в секундах можно задать через параметр командной строки:
     `python habrclient.py -t 10`, по умолчанию 20 секунд.  
    `URL` - домен по умолчанию, либо домен, полученный как параметр командной строки, если указан  
    `python habrclient.py -d 'https://habr.com'` - по умолчанию https://habr.com     
    `BASE_DIR = os.getcwd()` - текущая директория скрипта  
    `WORDS_FILE = 'words.txt'` - в этом файле будем хранить слова, которые потом будем считать  
    `DELAY_BETWEEN_REQUEST = 0.3` - задержка перед следующим запросом  
    `POPULAR_WORDS_LIMIT = 10` - ограничение, сколько наиболее часто используемых слов находить  
    `PREPOSITIONS` - предлоги, которые исключаем из подсчета
    
```
    RETRY_CODES = [413, 429, 500, 502, 503, 504] - коды ответов, от сервера при которых делаем повторный запрос
    RETRY_COUNT = 4     - количество повторных запросов, если запрос не удачный
    RETRY_TIMEOUT = 2   - сколько ждать ответа от сервера
    RETRY = True        - делать ли повторные запросы
    REPEAT_TIMEOUT = 2  - через сколько времени делать повторный запрос
```
3. Основная часть скрипта находится в файле `habrclient.py`.
    Есть базовый класс `BaseParser` в котором содержатся методы для выполнения запросов к серверу.  
      
    Есть класс наследник `HabrClient`, в котором содержится основная логика для сохранения страниц
    и подсчета слов, а также выполнения вспомогательных действий 
    (фильтрация предлогов, подсчет посещенных страниц, извлечение гиперссылок и тд).   
    Основной метод `run`, в нем вызываются вспомогательные методы и реализована основная логика.  
    В атрибуте `visited_urls` мы храним список посещенных страниц, чтобы повторно их не посещать.    
    В атрибуте `amount_pages_to_visit` - храним количество страниц, которое небходимо сохранить (посетить)  
    `result_words` - это список всех слов, кроме предлогов, которые мы будем подом считать.  
    В `frequency` - храним слова и число, означающее сколько раз оно встречалось.  
    Метод `show_words` - показывает N наиболее часто используемых слов. N берем из настроек
    (`POPULAR_WORDS_LIMIT` - по умолчанию 10)   
    
        
